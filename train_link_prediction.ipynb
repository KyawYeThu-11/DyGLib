{"cells":[{"cell_type":"markdown","metadata":{"id":"SrOiGmrTQBmv"},"source":["## Environmental Setup\n","\n","> Since it is impractical to download our dataset of sheer size in a reasonable time frame, we decided to have our implementations utilize the shared folder, which can be accessible from the mounted google drive. Therefore, for reproducibility, it is **IMPORTANT** to\n","1. Visit this [drive folder](https://drive.google.com/drive/folders/1VMn57KmlJ20DlviBlGufDC7vgdWIR9ni?usp=sharing).\n","2. Once visited, it'll show up in 'Shared with me' section in your google drive, from which you can add the shortcut to your drive.\n","3. Then, the shortcut should have the path, `drive/MyDrive/CS471 Project`.\n","\n","Mount Google Drive to the Colab VM and install necessary modules"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3765,"status":"ok","timestamp":1716694681831,"user":{"displayName":"Kyaw Ye Thu","userId":"15265666706494287045"},"user_tz":-540},"id":"ekk-FV3Hn40y","outputId":"fea00f9c-79e2-4d7d-c0bb-09dfe9821172"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"s1YuxS8qTA17","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716694691205,"user_tz":-540,"elapsed":9377,"user":{"displayName":"Kyaw Ye Thu","userId":"15265666706494287045"}},"outputId":"960c088b-53f7-4398-8f2a-01fa6368872f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (3.2)\n","/content\n"]}],"source":["!pip install wget\n","\n","import os\n","import shutil\n","import wget\n","from urllib.parse import urlparse\n","\n","%cd /content/\n","\n","repo_path = \"https://github.com/KyawYeThu-11/DyGLib.git\"\n","repo_name = os.path.splitext(os.path.basename(urlparse(repo_path).path))[0]\n","\n","if not os.path.exists(repo_name):\n","  !git clone $repo_path\n","  !pip install -r DyGLib/requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"u4Qx50hKysbZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716694691206,"user_tz":-540,"elapsed":11,"user":{"displayName":"Kyaw Ye Thu","userId":"15265666706494287045"}},"outputId":"c79f43db-0c7d-40c4-e44a-3579a8047307"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/DyGLib\n"]}],"source":["%cd /content/DyGLib"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"VYknFecnBLzG"},"outputs":[],"source":["import logging\n","import time\n","import sys\n","import os\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","import warnings\n","import shutil\n","import json\n","import torch\n","import torch.nn as nn\n","\n","from models.DyGFormer import DyGFormer\n","from models.modules import MergeLayer\n","from utils.utils import set_random_seed, convert_to_gpu, get_parameter_sizes, create_optimizer\n","from utils.utils import get_neighbor_sampler, NegativeEdgeSampler\n","from utils.metrics import get_link_prediction_metrics\n","from utils.DataLoader import get_idx_data_loader, get_link_prediction_data\n","from utils.EarlyStopping import EarlyStopping\n","from utils.load_configs import get_link_prediction_args"]},{"cell_type":"markdown","metadata":{"id":"8Zn_Gw0Qvb-x"},"source":["# Data Preprocessing"]},{"cell_type":"markdown","source":["The dataset, `train_0`, represents brain activations of a particular subject."],"metadata":{"id":"uriqDTHKxgSn"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1716686149618,"user":{"displayName":"Kyaw Ye Thu","userId":"15265666706494287045"},"user_tz":-540},"id":"yvlc-qXQ--Gk","outputId":"af11da9e-081e-4977-ec5c-66c7f8c73134"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'./DG_data/train_0/train_0.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}],"source":["dataset = 'train_0'\n","os.makedirs(f'./DG_data/{dataset}', exist_ok=True)\n","shutil.copy(f'../drive/MyDrive/CS471 Project/5-percentile-data/Train_Data_csv/dyn_a_0/{dataset}.csv', f'./DG_data/{dataset}')"]},{"cell_type":"markdown","metadata":{"id":"BfZcuZSx1PKi"},"source":["Or if you want to test with existing datasets."]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"PTrJznHyaeeA"},"outputs":[],"source":["# datasets = ['wikipedia', 'reddit', 'mooc', 'lastfm', 'myket', 'enron', 'SocialEvo', 'uci', 'Flights', 'CanParl', 'USLegis', 'UNtrade', 'UNvote', 'Contacts']\n","# dataset = 'CanParl'\n","# if not os.path.exists(dataset):\n","#   download_link = f\"https://zenodo.org/records/7213796/files/{dataset}.zip\"\n","#   wget.download(download_link, f\"{dataset}.zip\")\n","#   !unzip *.zip\n","#   !mv $dataset ./DG_data/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5355,"status":"ok","timestamp":1716686154967,"user":{"displayName":"Kyaw Ye Thu","userId":"15265666706494287045"},"user_tz":-540},"id":"tSL9xO4Xr0pg","outputId":"c92e9de2-3b9a-4674-9742-13fd4ba54c06","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/DyGLib/preprocess_data\n","preprocess dataset train_0...\n","number of nodes  400\n","number of node features  172\n","number of edges  400000\n","number of edge features  1\n","train_0 is processed successfully.\n","/content/DyGLib\n"]}],"source":["%cd preprocess_data\n","!python preprocess_data.py  --dataset_name $dataset\n","%cd .."]},{"cell_type":"markdown","metadata":{"id":"URXZEgpZvhwg"},"source":["# Training"]},{"cell_type":"markdown","source":["### Constants and Helper Functions"],"metadata":{"id":"6jir_UjtyTua"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hN_4YQGW4Hyd"},"outputs":[],"source":["class Args:\n","    def __init__(self, dataset_name):\n","        self.dataset_name = dataset_name\n","        self.batch_size = 1000\n","        self.model_name = 'DyGFormer'\n","        self.gpu = 0\n","        self.num_neighbors = 64\n","        self.sample_neighbor_strategy = 'recent'\n","        self.time_scaling_factor = 1e-6\n","        self.num_walk_heads = 8\n","        self.num_heads = 2\n","        self.num_layers = 2\n","        self.load_checkpoint = False\n","        self.walk_length = 1\n","        self.time_gap = 2000\n","        self.time_feat_dim = 100\n","        self.position_feat_dim = 172\n","        self.edge_bank_memory_mode = 'unlimited_memory'\n","        self.time_window_mode = 'fixed_proportion'\n","        self.patch_size = 2\n","        self.channel_embedding_dim = 50\n","        self.max_input_sequence_length = 64\n","        self.learning_rate = 0.0005\n","        self.dropout = 0.2\n","        self.num_epochs = 10\n","        self.optimizer = 'Adam'\n","        self.weight_decay = 0.0\n","        self.patience = 20\n","        self.val_ratio = 0.1\n","        self.test_ratio = 0.1\n","        self.num_runs = 3\n","        self.test_interval_epochs = 5\n","        self.negative_sample_strategy = 'random'\n","\n","    def __str__(self):\n","        properties = [f\"{key}={value}\" for key, value in self.__dict__.items()]\n","        return f\"Args({', '.join(properties)})\"\n","\n","    def __repr__(self):\n","        return self.__str__()\n","\n","# Create an instance of Args with the loaded configuration\n","args = Args(dataset_name = dataset)\n","args.device = f'cuda:{args.gpu}' if torch.cuda.is_available() and args.gpu >= 0 else 'cpu'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"515H-s4pJ7LJ"},"outputs":[],"source":["def set_up_logger(args):\n","        # set up logger\n","        logging.basicConfig(level=logging.INFO)\n","        logger = logging.getLogger()\n","        logger.setLevel(logging.DEBUG)\n","        os.makedirs(f\"./logs/{args.model_name}/{args.dataset_name}/{args.save_model_name}/\", exist_ok=True)\n","        # create file handler that logs debug and higher level messages\n","        fh = logging.FileHandler(f\"./logs/{args.model_name}/{args.dataset_name}/{args.save_model_name}/{str(time.time())}.log\")\n","        fh.setLevel(logging.DEBUG)\n","        # create console handler with a higher log level\n","        ch = logging.StreamHandler()\n","        ch.setLevel(logging.WARNING)\n","        # create formatter and add it to the handlers\n","        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n","        fh.setFormatter(formatter)\n","        ch.setFormatter(formatter)\n","        # add the handlers to logger\n","        logger.addHandler(fh)\n","        logger.addHandler(ch)\n","\n","        return logger, fh, ch"]},{"cell_type":"code","source":["def process_batch(batch_idx, data_indices, neg_edge_sampler, data, mode):\n","    data_indices = data_indices.numpy()\n","    batch_src_node_ids, batch_dst_node_ids, batch_node_interact_times, batch_edge_ids = \\\n","                data.src_node_ids[data_indices], data.dst_node_ids[data_indices], \\\n","                data.node_interact_times[data_indices], data.edge_ids[data_indices]\n","\n","\n","    if mode == 'train':\n","      _, batch_neg_dst_node_ids = neg_edge_sampler.sample(size=len(batch_src_node_ids))\n","      batch_neg_src_node_ids = batch_src_node_ids\n","    elif mode == 'val':\n","        if neg_edge_sampler.negative_sample_strategy != 'random':\n","            batch_neg_src_node_ids, batch_neg_dst_node_ids = neg_edge_sampler.sample(size=len(batch_src_node_ids),\n","                                                                                                  batch_src_node_ids=batch_src_node_ids,\n","                                                                                                  batch_dst_node_ids=batch_dst_node_ids,\n","                                                                                                  current_batch_start_time=batch_node_interact_times[0],\n","                                                                                                  current_batch_end_time=batch_node_interact_times[-1])\n","        else:\n","            _, batch_neg_dst_node_ids = neg_edge_sampler.sample(size=len(batch_src_node_ids))\n","            batch_neg_src_node_ids = batch_src_node_ids\n","\n","    # get temporal embedding of source and destination nodes\n","    # two Tensors, with shape (batch_size, node_feat_dim)\n","    batch_src_node_embeddings, batch_dst_node_embeddings = \\\n","          model[0].compute_src_dst_node_temporal_embeddings(src_node_ids=batch_src_node_ids,\n","                                                                          dst_node_ids=batch_dst_node_ids,\n","                                                                          node_interact_times=batch_node_interact_times)\n","\n","    # get temporal embedding of negative source and negative destination nodes\n","    # two Tensors, with shape (batch_size, node_feat_dim)\n","    batch_neg_src_node_embeddings, batch_neg_dst_node_embeddings = \\\n","          model[0].compute_src_dst_node_temporal_embeddings(src_node_ids=batch_neg_src_node_ids,\n","                                                                          dst_node_ids=batch_neg_dst_node_ids,\n","                                                                          node_interact_times=batch_node_interact_times)\n","\n","\n","\n","\n","\n","    # get positive and negative probabilities, shape (batch_size, )\n","    positive_probabilities = model[1](input_1=batch_src_node_embeddings, input_2=batch_dst_node_embeddings).squeeze(dim=-1).sigmoid()\n","    negative_probabilities = model[1](input_1=batch_neg_src_node_embeddings, input_2=batch_neg_dst_node_embeddings).squeeze(dim=-1).sigmoid()\n","\n","    predicts = torch.cat([positive_probabilities, negative_probabilities], dim=0)\n","    labels = torch.cat([torch.ones_like(positive_probabilities), torch.zeros_like(negative_probabilities)], dim=0)\n","\n","    loss = loss_func(input=predicts, target=labels)\n","\n","    return predicts, loss, labels"],"metadata":{"id":"jOU0XX77UsJ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_model_link_prediction(model, neighbor_sampler, evaluate_idx_data_loader, evaluate_data):\n","        model.eval()\n","\n","        model[0].set_neighbor_sampler(neighbor_sampler)\n","\n","        with torch.no_grad():\n","          # store evaluate losses and metrics\n","          evaluate_losses, evaluate_metrics = [], []\n","          evaluate_idx_data_loader_tqdm = tqdm(evaluate_idx_data_loader, ncols=120)\n","          for batch_idx, evaluate_data_indices in enumerate(evaluate_idx_data_loader_tqdm):\n","            predicts, loss, labels = process_batch(batch_idx, evaluate_data_indices, val_neg_edge_sampler, evaluate_data, 'val')\n","\n","            evaluate_losses.append(loss.item())\n","            evaluate_metrics.append(get_link_prediction_metrics(predicts=predicts, labels=labels))\n","\n","            evaluate_idx_data_loader_tqdm.set_description(f'evaluate for the {batch_idx + 1}-th batch, evaluate loss: {loss.item()}')\n","\n","          return evaluate_losses, evaluate_metrics"],"metadata":{"id":"tTN4xURC8Cp1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Main"],"metadata":{"id":"YrNy2nas4gNS"}},{"cell_type":"code","source":[" # get data for training, validation and testing\n","node_raw_features, edge_raw_features, full_data, train_data, val_data, test_data, _, _ = \\\n","get_link_prediction_data(dataset_name=args.dataset_name, val_ratio=args.val_ratio, test_ratio=args.test_ratio)\n","\n","# initialize training neighbor sampler to retrieve temporal graph\n","train_neighbor_sampler = get_neighbor_sampler(data=train_data, sample_neighbor_strategy=args.sample_neighbor_strategy,\n","                                                  time_scaling_factor=args.time_scaling_factor, seed=0)\n","\n","# initialize validation and test neighbor sampler to retrieve temporal graph\n","full_neighbor_sampler = get_neighbor_sampler(data=full_data, sample_neighbor_strategy=args.sample_neighbor_strategy,\n","                                                 time_scaling_factor=args.time_scaling_factor, seed=1)\n","\n","# initialize negative samplers, set seeds for validation and testing so negatives are the same across different runs\n","# in the inductive setting, negatives are sampled only amongst other new nodes\n","# train negative edge sampler does not need to specify the seed, but evaluation samplers need to do so\n","train_neg_edge_sampler = NegativeEdgeSampler(src_node_ids=train_data.src_node_ids, dst_node_ids=train_data.dst_node_ids)\n","val_neg_edge_sampler = NegativeEdgeSampler(src_node_ids=full_data.src_node_ids, dst_node_ids=full_data.dst_node_ids, seed=0)\n","test_neg_edge_sampler = NegativeEdgeSampler(src_node_ids=full_data.src_node_ids, dst_node_ids=full_data.dst_node_ids, seed=2)\n","\n","# get data loaders\n","train_idx_data_loader = get_idx_data_loader(indices_list=list(range(len(train_data.src_node_ids))), batch_size=args.batch_size, shuffle=False)\n","val_idx_data_loader = get_idx_data_loader(indices_list=list(range(len(val_data.src_node_ids))), batch_size=args.batch_size, shuffle=False)\n","test_idx_data_loader = get_idx_data_loader(indices_list=list(range(len(test_data.src_node_ids))), batch_size=args.batch_size, shuffle=False)\n","\n","val_metric_all_runs, test_metric_all_runs  = [], []"],"metadata":{"id":"AvAawHm9Rf2L","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716694697416,"user_tz":-540,"elapsed":5831,"user":{"displayName":"Kyaw Ye Thu","userId":"15265666706494287045"}},"outputId":"7aaeda23-c9d4-44c3-bc77-943fe021fc24","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The dataset has 400000 interactions, involving 400 different nodes\n","The training dataset has 265436 interactions, involving 360 different nodes\n","The validation dataset has 40000 interactions, involving 400 different nodes\n","The test dataset has 40000 interactions, involving 400 different nodes\n","The new node validation dataset has 6044 interactions, involving 306 different nodes\n","The new node test dataset has 7446 interactions, involving 279 different nodes\n","40 nodes were used for the inductive testing, i.e. are never seen during training\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"GRR-DP0RKJj6","outputId":"0e95e023-3dfa-4306-f64b-37df215784b2","executionInfo":{"status":"error","timestamp":1716694711032,"user_tz":-540,"elapsed":13626,"user":{"displayName":"Kyaw Ye Thu","userId":"15265666706494287045"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["INFO:root:********** Run 1 starts. **********\n","INFO:root:configuration is Args(dataset_name=train_0, batch_size=1000, model_name=DyGFormer, gpu=0, num_neighbors=64, sample_neighbor_strategy=recent, time_scaling_factor=1e-06, num_walk_heads=8, num_heads=2, num_layers=2, load_checkpoint=False, walk_length=1, time_gap=2000, time_feat_dim=100, position_feat_dim=172, edge_bank_memory_mode=unlimited_memory, time_window_mode=fixed_proportion, patch_size=2, channel_embedding_dim=50, max_input_sequence_length=64, learning_rate=0.0005, dropout=0.2, num_epochs=10, optimizer=Adam, weight_decay=0.0, patience=20, val_ratio=0.1, test_ratio=0.1, num_runs=3, test_interval_epochs=5, negative_sample_strategy=random, device=cpu, seed=0, save_model_name=DyGFormer_seed0)\n","INFO:root:model -> Sequential(\n","  (0): DyGFormer(\n","    (time_encoder): TimeEncoder(\n","      (w): Linear(in_features=1, out_features=100, bias=True)\n","    )\n","    (neighbor_co_occurrence_encoder): NeighborCooccurrenceEncoder(\n","      (neighbor_co_occurrence_encode_layer): Sequential(\n","        (0): Linear(in_features=1, out_features=50, bias=True)\n","        (1): ReLU()\n","        (2): Linear(in_features=50, out_features=50, bias=True)\n","      )\n","    )\n","    (projection_layer): ModuleDict(\n","      (node): Linear(in_features=344, out_features=50, bias=True)\n","      (edge): Linear(in_features=344, out_features=50, bias=True)\n","      (time): Linear(in_features=200, out_features=50, bias=True)\n","      (neighbor_co_occurrence): Linear(in_features=100, out_features=50, bias=True)\n","    )\n","    (transformers): ModuleList(\n","      (0-1): 2 x TransformerEncoder(\n","        (multi_head_attention): MultiheadAttention(\n","          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n","        )\n","        (dropout): Dropout(p=0.2, inplace=False)\n","        (linear_layers): ModuleList(\n","          (0): Linear(in_features=200, out_features=800, bias=True)\n","          (1): Linear(in_features=800, out_features=200, bias=True)\n","        )\n","        (norm_layers): ModuleList(\n","          (0-1): 2 x LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (output_layer): Linear(in_features=200, out_features=172, bias=True)\n","  )\n","  (1): MergeLayer(\n","    (fc1): Linear(in_features=344, out_features=172, bias=True)\n","    (fc2): Linear(in_features=172, out_features=1, bias=True)\n","    (act): ReLU()\n","  )\n",")\n","INFO:root:model name: DyGFormer, #parameters: 4446940 B, 4342.71484375 KB, 4.240932464599609 MB.\n","Epoch: 0, train for the 3-th batch, train loss: 0.7011621594429016:   1%|▏              | 3/266 [00:09<14:32,  3.32s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-b1524e910157>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","for run in range(args.num_runs):\n","    set_random_seed(seed=run)\n","    args.seed = run\n","\n","    args.save_model_name = f'{args.model_name}_seed{args.seed}'\n","    save_model_folder = f\"/content/drive/MyDrive/CS471 Project/saved_models/link_prediction/{args.dataset_name}\"\n","    checkpoint_path = os.path.join(save_model_folder, f'{args.save_model_name}.pth')\n","\n","    logger, fh, ch = set_up_logger(args)\n","\n","    run_start_time = time.time()\n","    logger.info(f\"********** Run {run + 1} starts. **********\")\n","\n","    logger.info(f'configuration is {args}')\n","\n","    # Initialize the model\n","    dynamic_backbone = DyGFormer(node_raw_features=node_raw_features, edge_raw_features=edge_raw_features, neighbor_sampler=train_neighbor_sampler,\n","                                time_feat_dim=args.time_feat_dim, channel_embedding_dim=args.channel_embedding_dim, patch_size=args.patch_size,\n","                                num_layers=args.num_layers, num_heads=args.num_heads, dropout=args.dropout,\n","                                max_input_sequence_length=args.max_input_sequence_length, device=args.device)\n","\n","    link_predictor = MergeLayer(input_dim1=node_raw_features.shape[1], input_dim2=node_raw_features.shape[1],\n","                                    hidden_dim=node_raw_features.shape[1], output_dim=1)\n","    model = nn.Sequential(dynamic_backbone, link_predictor)\n","\n","    # log the model structure\n","    logger.info(f'model -> {model}')\n","    logger.info(f'model name: {args.model_name}, #parameters: {get_parameter_sizes(model) * 4} B, '\n","                    f'{get_parameter_sizes(model) * 4 / 1024} KB, {get_parameter_sizes(model) * 4 / 1024 / 1024} MB.')\n","\n","    # Create the optimizer with specified parameters\n","    optimizer = create_optimizer(model=model, optimizer_name=args.optimizer, learning_rate=args.learning_rate, weight_decay=args.weight_decay)\n","\n","    # Convert the model to GPU if available\n","    model = convert_to_gpu(model, device=args.device)\n","\n","    os.makedirs(save_model_folder, exist_ok=True)\n","\n","    # Initialize early stopping mechanism with the given patience and save model parameters\n","    early_stopping = EarlyStopping(patience=args.patience, save_model_folder=save_model_folder,\n","                                       save_model_name=args.save_model_name, logger=logger, model_name=args.model_name)\n","\n","    epoch_resumed = 0\n","    # Load checkpoint if specified and exists\n","    if args.load_checkpoint == True and os.path.exists(checkpoint_path):\n","        checkpoint = torch.load(checkpoint_path, map_location=args.device)\n","        logger.info(f\"load model {checkpoint_path}\")\n","        early_stopping.load_checkpoint(model, checkpoint)\n","        epoch_resumed = checkpoint['epoch'] + 1\n","        print(f\"Epoch resumed: {epoch_resumed}\")\n","\n","    # Define the binary cross-entropy loss function\n","    loss_func = nn.BCELoss()\n","\n","    for epoch in range(epoch_resumed, args.num_epochs, 1):\n","\n","        # Training for an epoch starts\n","        model.train()\n","\n","        model[0].set_neighbor_sampler(train_neighbor_sampler)\n","        train_losses, train_metrics = [], []\n","        train_idx_data_loader_tqdm = tqdm(train_idx_data_loader, ncols=120)\n","\n","        for batch_idx, train_data_indices in enumerate(train_idx_data_loader_tqdm):\n","          # Process each batch and compute predictions, loss, and labels\n","          predicts, loss, labels = process_batch(batch_idx, train_data_indices, train_neg_edge_sampler, train_data, 'train')\n","\n","          train_losses.append(loss.item())\n","          train_metrics.append(get_link_prediction_metrics(predicts=predicts, labels=labels))\n","\n","          optimizer.zero_grad()\n","          loss.backward()\n","          optimizer.step()\n","\n","          train_idx_data_loader_tqdm.set_description(f'Epoch: {epoch}, train for the {batch_idx + 1}-th batch, train loss: {loss.item()}')\n","\n","        # Get validation metrics\n","        val_losses, val_metrics = evaluate_model_link_prediction(model, full_neighbor_sampler, val_idx_data_loader, val_data)\n","\n","        # Log the training and validation metrics\n","        logger.info(f'Epoch: {epoch + 1}, learning rate: {optimizer.param_groups[0][\"lr\"]}, train loss: {np.mean(train_losses):.4f}')\n","        for metric_name in train_metrics[0].keys():\n","            logger.info(f'train {metric_name}, {np.mean([train_metric[metric_name] for train_metric in train_metrics]):.4f}')\n","        logger.info(f'validate loss: {np.mean(val_losses):.4f}')\n","        for metric_name in val_metrics[0].keys():\n","            logger.info(f'validate {metric_name}, {np.mean([val_metric[metric_name] for val_metric in val_metrics]):.4f}')\n","\n","\n","        # perform testing once after test_interval_epochs\n","        if (epoch + 1) % args.test_interval_epochs == 0:\n","            test_losses, test_metrics = evaluate_model_link_prediction(model, full_neighbor_sampler, test_idx_data_loader, test_data)\n","\n","            # Log the test metrics\n","            logger.info(f'test loss: {np.mean(test_losses):.4f}')\n","            for metric_name in test_metrics[0].keys():\n","                logger.info(f'test {metric_name}, {np.mean([test_metric[metric_name] for test_metric in test_metrics]):.4f}')\n","\n","        # select the best model based on all the validate metrics\n","        val_metric_indicator = []\n","        for metric_name in val_metrics[0].keys():\n","          val_metric_indicator.append((metric_name, np.mean([val_metric[metric_name] for val_metric in val_metrics]), True))\n","\n","        early_stop = early_stopping.step(val_metric_indicator, epoch, model)\n","\n","        if early_stop:\n","            break # Stop training if early stopping condition is met\n","\n","    # Load the best model\n","    checkpoint = torch.load(checkpoint_path, map_location=args.device)\n","    early_stopping.load_checkpoint(model, checkpoint)\n","\n","    # Evaluate the best model on the test set\n","    logger.info(f'get final performance on dataset {args.dataset_name}...')\n","    test_losses, test_metrics = evaluate_model_link_prediction(model, full_neighbor_sampler, test_idx_data_loader, test_data)\n","\n","    # Store the evaluation metrics at the current run\n","    test_metric_dict = {}\n","\n","    logger.info(f'test loss: {np.mean(test_losses):.4f}')\n","    for metric_name in test_metrics[0].keys():\n","        average_test_metric = np.mean([test_metric[metric_name] for test_metric in test_metrics])\n","        logger.info(f'test {metric_name}, {average_test_metric:.4f}')\n","        test_metric_dict[metric_name] = average_test_metric\n","\n","    single_run_time = time.time() - run_start_time\n","    logger.info(f'Run {run + 1} cost {single_run_time:.2f} seconds.')\n","    test_metric_all_runs.append(test_metric_dict)\n","\n","    # avoid the overlap of logs\n","    if run < args.num_runs - 1:\n","        logger.removeHandler(fh)\n","        logger.removeHandler(ch)\n","\n","    # Save the results of the current run to a JSON file\n","    result_json = {\"test metrics\": {metric_name: f'{test_metric_dict[metric_name]:.4f}' for metric_name in test_metric_dict}}\n","    result_json = json.dumps(result_json, indent=4)\n","\n","    save_result_folder = f\"/content/drive/MyDrive/CS471 Project/saved_results/link_prediction/{args.dataset_name}\"\n","    os.makedirs(save_result_folder, exist_ok=True)\n","    save_result_path = os.path.join(save_result_folder, f\"{args.save_model_name}.json\")\n","\n","    with open(save_result_path, 'w') as file:\n","        file.write(result_json)\n","\n","# store the average metrics at the log of the last run\n","logger.info(f'metrics over {args.num_runs} runs:')\n","\n","# Log the metrics over all runs\n","for metric_name in test_metric_all_runs[0].keys():\n","    logger.info(f'test {metric_name}, {[test_metric_single_run[metric_name] for test_metric_single_run in test_metric_all_runs]}')\n","    logger.info(f'average test {metric_name}, {np.mean([test_metric_single_run[metric_name] for test_metric_single_run in test_metric_all_runs]):.4f} '\n","                    f'± {np.std([test_metric_single_run[metric_name] for test_metric_single_run in test_metric_all_runs], ddof=1):.4f}')"]},{"cell_type":"markdown","source":["# Testing & Inferencing"],"metadata":{"id":"4p5xTFkKR3nB"}},{"cell_type":"markdown","source":["Choose a model."],"metadata":{"id":"q-TENevi-7xP"}},{"cell_type":"code","source":["# Initialize the model\n","dynamic_backbone = DyGFormer(node_raw_features=node_raw_features, edge_raw_features=edge_raw_features, neighbor_sampler=train_neighbor_sampler,\n","                                time_feat_dim=args.time_feat_dim, channel_embedding_dim=args.channel_embedding_dim, patch_size=args.patch_size,\n","                                num_layers=args.num_layers, num_heads=args.num_heads, dropout=args.dropout,\n","                                max_input_sequence_length=args.max_input_sequence_length, device=args.device)\n","\n","link_predictor = MergeLayer(input_dim1=node_raw_features.shape[1], input_dim2=node_raw_features.shape[1],\n","                                    hidden_dim=node_raw_features.shape[1], output_dim=1)\n","model = nn.Sequential(dynamic_backbone, link_predictor)\n","\n","model = convert_to_gpu(model, device=args.device)\n","\n","# Load the pretrained model from the specified path\n","load_model_path = f\"/content/drive/MyDrive/CS471 Project/saved_models/link_prediction/train_0/DyGFormer_seed2.pth\"\n","checkpoint = torch.load(load_model_path, map_location=args.device)\n","model.load_state_dict(checkpoint['model_state_dict'])"],"metadata":{"id":"nVWI6p02-9nv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Test the model with the testing set."],"metadata":{"id":"e8kIa84g_BdW"}},{"cell_type":"code","source":["test_losses, test_metrics = evaluate_model_link_prediction(model, full_neighbor_sampler, test_idx_data_loader, test_data)\n","\n","# Store the evaluation metrics at the current run\n","test_metric_dict = {}\n","print(f'test loss: {np.mean(test_losses):.4f}')\n","\n","for metric_name in test_metrics[0].keys():\n","    average_test_metric = np.mean([test_metric[metric_name] for test_metric in test_metrics])\n","    print(f'test {metric_name}, {average_test_metric:.4f}')\n","    test_metric_dict[metric_name] = average_test_metric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":390},"collapsed":true,"id":"5yhKmgCL9v2i","executionInfo":{"status":"error","timestamp":1716694791150,"user_tz":-540,"elapsed":41754,"user":{"displayName":"Kyaw Ye Thu","userId":"15265666706494287045"}},"outputId":"a54d0365-d1e6-4c6e-ccf0-9ea5a835d56d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["evaluate for the 2-th batch, evaluate loss: 0.3169395327568054:   5%|█                   | 2/40 [00:40<12:56, 20.44s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-4c6e20200362>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtest_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model_link_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_neighbor_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Store the evaluation metrics at the current run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-22-055ec0d943b1>\u001b[0m in \u001b[0;36mevaluate_model_link_prediction\u001b[0;34m(model, neighbor_sampler, evaluate_idx_data_loader, evaluate_data)\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mevaluate_idx_data_loader_tqdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_idx_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_data_indices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_idx_data_loader_tqdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mpredicts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_data_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_neg_edge_sampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mevaluate_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-64fd40cd5a22>\u001b[0m in \u001b[0;36mprocess_batch\u001b[0;34m(batch_idx, data_indices, neg_edge_sampler, data, mode)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# two Tensors, with shape (batch_size, node_feat_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mbatch_neg_src_node_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_neg_dst_node_embeddings\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m           model[0].compute_src_dst_node_temporal_embeddings(src_node_ids=batch_neg_src_node_ids,\n\u001b[0m\u001b[1;32m     33\u001b[0m                                                                           \u001b[0mdst_node_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_neg_dst_node_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                                                           node_interact_times=batch_node_interact_times)\n","\u001b[0;32m/content/DyGLib/models/DyGFormer.py\u001b[0m in \u001b[0;36mcompute_src_dst_node_temporal_embeddings\u001b[0;34m(self, src_node_ids, dst_node_ids, node_interact_times)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;31m# Tensor, shape (batch_size, src_num_patches + dst_num_patches, num_channels * channel_embedding_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtransformer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0mpatches_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# H^t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;31m# src_patches_data, Tensor, shape (batch_size, src_num_patches, num_channels * channel_embedding_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/DyGLib/models/DyGFormer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;31m# Tensor, shape (batch_size, num_patches, self.attention_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;31m# Tensor, shape (batch_size, num_patches, self.attention_dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["See how the model performs with custom inputs."],"metadata":{"id":"rj_Xpwjq_GnX"}},{"cell_type":"code","source":["# Initialize the model\n","dynamic_backbone = DyGFormer(node_raw_features=node_raw_features, edge_raw_features=edge_raw_features, neighbor_sampler=train_neighbor_sampler,\n","                                time_feat_dim=args.time_feat_dim, channel_embedding_dim=args.channel_embedding_dim, patch_size=args.patch_size,\n","                                num_layers=args.num_layers, num_heads=args.num_heads, dropout=args.dropout,\n","                                max_input_sequence_length=args.max_input_sequence_length, device=args.device)\n","\n","link_predictor = MergeLayer(input_dim1=node_raw_features.shape[1], input_dim2=node_raw_features.shape[1],\n","                                    hidden_dim=node_raw_features.shape[1], output_dim=1)\n","model = nn.Sequential(dynamic_backbone, link_predictor)\n","\n","model = convert_to_gpu(model, device=args.device)\n","\n","# Load the pretrained model from the specified path\n","load_model_path = f\"/content/drive/MyDrive/CS471 Project/saved_models/link_prediction/train_0/DyGFormer_seed2.pth\"\n","checkpoint = torch.load(load_model_path, map_location=args.device)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","\n","# Set threshold and data generation parameters\n","threshold = 0.31 # should be around 0.3\n","each_occurance = 100 # must be < 400\n","size = 10000 # must be < 160000 (400 * 400)\n","\n","# Generate an array of node IDs with specified occurrences (array of 100 times one, 100 times two, etc.)\n","base_array = np.repeat(np.arange(0, 400), each_occurance)\n","first_node_ids = np.sort(np.random.choice(base_array, size=size, replace=False))\n","second_node_ids = np.random.choice(base_array, size=size, replace=False)\n","node_interact_times = np.zeros(size)\n","\n","# unique, counts = np.unique(second_node_ids, return_counts=True)\n","# print(f\"occurance: {dict(zip(unique, counts))}\")\n","\n","# Compute source and destination node temporal embeddings using the model\n","first_node_embeddings, second_node_embeddings = \\\n","model[0].compute_src_dst_node_temporal_embeddings(src_node_ids=first_node_ids,\n","                                                  dst_node_ids=second_node_ids,\n","                                                  node_interact_times=node_interact_times)\n","\n","# Predict link probabilities\n","probabilities = model[1](input_1=first_node_embeddings, input_2=second_node_embeddings).squeeze(dim=-1).sigmoid()\n","\n","# Determine the links based on the threshold\n","link = np.where(probabilities.detach().cpu() > threshold, 1, 0)\n","\n","# Create a DataFrame to store the inference results\n","inference_df = pd.DataFrame({\n","    'first_nodes': first_node_ids,\n","    'second_nodes': second_node_ids,\n","    'link': link\n","    })\n","\n","inference_df = inference_df.drop_duplicates()\n","inference_df = inference_df.sort_values(by=['first_nodes', 'link', 'second_nodes'])\n","inference_df"],"metadata":{"id":"20eJQ6dM47Ql","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1716686467900,"user_tz":-540,"elapsed":5448,"user":{"displayName":"Kyaw Ye Thu","userId":"15265666706494287045"}},"outputId":"ed8f4751-4912-4b71-c00f-a0d3cb136576"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      first_nodes  second_nodes  link\n","3               0           119     0\n","23              0           272     0\n","6               0           371     0\n","13              0            38     1\n","10              0            62     1\n","...           ...           ...   ...\n","9991          399           277     1\n","9985          399           286     1\n","9988          399           305     1\n","9984          399           343     1\n","9996          399           380     1\n","\n","[9816 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-487d1631-9f72-4d2e-ac4f-cf3b962b654c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_nodes</th>\n","      <th>second_nodes</th>\n","      <th>link</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>119</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0</td>\n","      <td>272</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0</td>\n","      <td>371</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0</td>\n","      <td>38</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0</td>\n","      <td>62</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9991</th>\n","      <td>399</td>\n","      <td>277</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9985</th>\n","      <td>399</td>\n","      <td>286</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9988</th>\n","      <td>399</td>\n","      <td>305</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9984</th>\n","      <td>399</td>\n","      <td>343</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>399</td>\n","      <td>380</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9816 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-487d1631-9f72-4d2e-ac4f-cf3b962b654c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-487d1631-9f72-4d2e-ac4f-cf3b962b654c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-487d1631-9f72-4d2e-ac4f-cf3b962b654c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-bff8a60b-be21-4d66-b5b8-a03e48862345\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bff8a60b-be21-4d66-b5b8-a03e48862345')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-bff8a60b-be21-4d66-b5b8-a03e48862345 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_0982c544-a7dd-476d-8956-cdce5110dcd0\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('inference_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_0982c544-a7dd-476d-8956-cdce5110dcd0 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('inference_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"inference_df","summary":"{\n  \"name\": \"inference_df\",\n  \"rows\": 9816,\n  \"fields\": [\n    {\n      \"column\": \"first_nodes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 399,\n        \"num_unique_values\": 400,\n        \"samples\": [\n          209,\n          280,\n          33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"second_nodes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 399,\n        \"num_unique_values\": 400,\n        \"samples\": [\n          9,\n          327,\n          95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":[],"metadata":{"id":"uV4dkRY-qC7H"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["SrOiGmrTQBmv","8Zn_Gw0Qvb-x","6jir_UjtyTua","YrNy2nas4gNS","4p5xTFkKR3nB"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
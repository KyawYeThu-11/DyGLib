{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrOiGmrTQBmv"
      },
      "source": [
        "## Environmental Setup\n",
        "\n",
        "Install necessary modules and clone the Github repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "s1YuxS8qTA17",
        "outputId": "4cc139d8-11a4-4802-a736-5d89d3de7649"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=f4661507a08243e3e53c6644ee95ac2a396713f9f4c5b3f88fca2beb97278f36\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "/content\n",
            "Cloning into 'DyGLib'...\n",
            "remote: Enumerating objects: 435, done.\u001b[K\n",
            "remote: Counting objects: 100% (378/378), done.\u001b[K\n",
            "remote: Compressing objects: 100% (260/260), done.\u001b[K\n",
            "remote: Total 435 (delta 137), reused 332 (delta 111), pack-reused 57\u001b[K\n",
            "Receiving objects: 100% (435/435), 226.83 MiB | 15.72 MiB/s, done.\n",
            "Resolving deltas: 100% (149/149), done.\n",
            "Updating files: 100% (231/231), done.\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from -r DyGLib/requirements.txt (line 1)) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r DyGLib/requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r DyGLib/requirements.txt (line 3)) (2.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r DyGLib/requirements.txt (line 4)) (4.66.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from -r DyGLib/requirements.txt (line 5)) (0.9.0)\n",
            "Collecting torch-geometric (from -r DyGLib/requirements.txt (line 6))\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->-r DyGLib/requirements.txt (line 1)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.1->-r DyGLib/requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->-r DyGLib/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r DyGLib/requirements.txt (line 3)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r DyGLib/requirements.txt (line 3)) (2024.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric->-r DyGLib/requirements.txt (line 6)) (1.11.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric->-r DyGLib/requirements.txt (line 6)) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric->-r DyGLib/requirements.txt (line 6)) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric->-r DyGLib/requirements.txt (line 6)) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric->-r DyGLib/requirements.txt (line 6)) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric->-r DyGLib/requirements.txt (line 6)) (5.9.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->-r DyGLib/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric->-r DyGLib/requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric->-r DyGLib/requirements.txt (line 6)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric->-r DyGLib/requirements.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric->-r DyGLib/requirements.txt (line 6)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric->-r DyGLib/requirements.txt (line 6)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric->-r DyGLib/requirements.txt (line 6)) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->-r DyGLib/requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric->-r DyGLib/requirements.txt (line 6)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric->-r DyGLib/requirements.txt (line 6)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric->-r DyGLib/requirements.txt (line 6)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric->-r DyGLib/requirements.txt (line 6)) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric->-r DyGLib/requirements.txt (line 6)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric->-r DyGLib/requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->-r DyGLib/requirements.txt (line 1)) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, torch-geometric, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torch-geometric-2.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install wget\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import wget\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "repo_path = \"https://github.com/KyawYeThu-11/DyGLib.git\"\n",
        "repo_name = os.path.splitext(os.path.basename(urlparse(repo_path).path))[0]\n",
        "\n",
        "if not os.path.exists(repo_name):\n",
        "  !git clone $repo_path\n",
        "  !pip install -r DyGLib/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "u4Qx50hKysbZ",
        "outputId": "ae58efcd-6793-4637-d6cb-7be076a3996d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DyGLib\n"
          ]
        }
      ],
      "source": [
        "%cd /content/DyGLib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VYknFecnBLzG"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import time\n",
        "import sys\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import shutil\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from models.DyGFormer import DyGFormer\n",
        "from models.modules import MergeLayer\n",
        "from utils.utils import set_random_seed, convert_to_gpu, get_parameter_sizes, create_optimizer\n",
        "from utils.utils import get_neighbor_sampler, NegativeEdgeSampler\n",
        "from utils.metrics import get_link_prediction_metrics\n",
        "from utils.DataLoader import get_idx_data_loader, get_link_prediction_data\n",
        "from utils.EarlyStopping import EarlyStopping\n",
        "from utils.load_configs import get_link_prediction_args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zn_Gw0Qvb-x"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uriqDTHKxgSn"
      },
      "source": [
        "The dataset, `train_0`, represents brain activations of a particular subject."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yvlc-qXQ--Gk",
        "outputId": "b2ac0a7a-82b4-4804-c99c-0e6743c47e9d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./DG_data/train_0/train_0.csv'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = 'train_0'\n",
        "os.makedirs(f'./DG_data/{dataset}', exist_ok=True)\n",
        "shutil.copy(f'./DG_data/connectome/5-percentile/Train_Data_csv/{dataset}.csv', f'./DG_data/{dataset}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfZcuZSx1PKi"
      },
      "source": [
        "Or if you want to test with existing datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "PTrJznHyaeeA"
      },
      "outputs": [],
      "source": [
        "# datasets = ['wikipedia', 'reddit', 'mooc', 'lastfm', 'myket', 'enron', 'SocialEvo', 'uci', 'Flights', 'CanParl', 'USLegis', 'UNtrade', 'UNvote', 'Contacts']\n",
        "# dataset = 'CanParl'\n",
        "# if not os.path.exists(dataset):\n",
        "#   download_link = f\"https://zenodo.org/records/7213796/files/{dataset}.zip\"\n",
        "#   wget.download(download_link, f\"{dataset}.zip\")\n",
        "#   !unzip *.zip\n",
        "#   !mv $dataset ./DG_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tSL9xO4Xr0pg",
        "outputId": "f7dacf24-26df-426d-df43-efd7b7a55e6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/DyGLib/preprocess_data\n",
            "preprocess dataset train_0...\n",
            "number of nodes  400\n",
            "number of node features  172\n",
            "number of edges  400000\n",
            "number of edge features  1\n",
            "train_0 is processed successfully.\n",
            "/content/DyGLib\n"
          ]
        }
      ],
      "source": [
        "%cd preprocess_data\n",
        "!python preprocess_data.py  --dataset_name $dataset\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URXZEgpZvhwg"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jir_UjtyTua"
      },
      "source": [
        "### Constants and Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN_4YQGW4Hyd"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    def __init__(self, dataset_name):\n",
        "        self.dataset_name = dataset_name\n",
        "        self.batch_size = 1000\n",
        "        self.model_name = 'DyGFormer'\n",
        "        self.gpu = 0\n",
        "        self.num_neighbors = 64\n",
        "        self.sample_neighbor_strategy = 'recent'\n",
        "        self.time_scaling_factor = 1e-6\n",
        "        self.num_walk_heads = 8\n",
        "        self.num_heads = 2\n",
        "        self.num_layers = 2\n",
        "        self.load_checkpoint = False\n",
        "        self.walk_length = 1\n",
        "        self.time_gap = 2000\n",
        "        self.time_feat_dim = 100\n",
        "        self.position_feat_dim = 172\n",
        "        self.edge_bank_memory_mode = 'unlimited_memory'\n",
        "        self.time_window_mode = 'fixed_proportion'\n",
        "        self.patch_size = 2\n",
        "        self.channel_embedding_dim = 50\n",
        "        self.max_input_sequence_length = 64\n",
        "        self.learning_rate = 0.0005\n",
        "        self.dropout = 0.2\n",
        "        self.num_epochs = 10\n",
        "        self.optimizer = 'Adam'\n",
        "        self.weight_decay = 0.0\n",
        "        self.patience = 20\n",
        "        self.val_ratio = 0.1\n",
        "        self.test_ratio = 0.1\n",
        "        self.num_runs = 3\n",
        "        self.test_interval_epochs = 5\n",
        "        self.negative_sample_strategy = 'random'\n",
        "\n",
        "    def __str__(self):\n",
        "        properties = [f\"{key}={value}\" for key, value in self.__dict__.items()]\n",
        "        return f\"Args({', '.join(properties)})\"\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__str__()\n",
        "\n",
        "# Create an instance of Args with the loaded configuration\n",
        "args = Args(dataset_name = dataset)\n",
        "args.device = f'cuda:{args.gpu}' if torch.cuda.is_available() and args.gpu >= 0 else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "515H-s4pJ7LJ"
      },
      "outputs": [],
      "source": [
        "def set_up_logger(args):\n",
        "        # set up logger\n",
        "        logging.basicConfig(level=logging.INFO)\n",
        "        logger = logging.getLogger()\n",
        "        logger.setLevel(logging.DEBUG)\n",
        "        os.makedirs(f\"./logs/{args.model_name}/{args.dataset_name}/{args.save_model_name}/\", exist_ok=True)\n",
        "        # create file handler that logs debug and higher level messages\n",
        "        fh = logging.FileHandler(f\"./logs/{args.model_name}/{args.dataset_name}/{args.save_model_name}/{str(time.time())}.log\")\n",
        "        fh.setLevel(logging.DEBUG)\n",
        "        # create console handler with a higher log level\n",
        "        ch = logging.StreamHandler()\n",
        "        ch.setLevel(logging.WARNING)\n",
        "        # create formatter and add it to the handlers\n",
        "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "        fh.setFormatter(formatter)\n",
        "        ch.setFormatter(formatter)\n",
        "        # add the handlers to logger\n",
        "        logger.addHandler(fh)\n",
        "        logger.addHandler(ch)\n",
        "\n",
        "        return logger, fh, ch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOU0XX77UsJ7"
      },
      "outputs": [],
      "source": [
        "def process_batch(batch_idx, data_indices, neg_edge_sampler, data, mode):\n",
        "    data_indices = data_indices.numpy()\n",
        "    batch_src_node_ids, batch_dst_node_ids, batch_node_interact_times, batch_edge_ids = \\\n",
        "                data.src_node_ids[data_indices], data.dst_node_ids[data_indices], \\\n",
        "                data.node_interact_times[data_indices], data.edge_ids[data_indices]\n",
        "\n",
        "\n",
        "    if mode == 'train':\n",
        "      _, batch_neg_dst_node_ids = neg_edge_sampler.sample(size=len(batch_src_node_ids))\n",
        "      batch_neg_src_node_ids = batch_src_node_ids\n",
        "    elif mode == 'val':\n",
        "        if neg_edge_sampler.negative_sample_strategy != 'random':\n",
        "            batch_neg_src_node_ids, batch_neg_dst_node_ids = neg_edge_sampler.sample(size=len(batch_src_node_ids),\n",
        "                                                                                                  batch_src_node_ids=batch_src_node_ids,\n",
        "                                                                                                  batch_dst_node_ids=batch_dst_node_ids,\n",
        "                                                                                                  current_batch_start_time=batch_node_interact_times[0],\n",
        "                                                                                                  current_batch_end_time=batch_node_interact_times[-1])\n",
        "        else:\n",
        "            _, batch_neg_dst_node_ids = neg_edge_sampler.sample(size=len(batch_src_node_ids))\n",
        "            batch_neg_src_node_ids = batch_src_node_ids\n",
        "\n",
        "    # get temporal embedding of source and destination nodes\n",
        "    # two Tensors, with shape (batch_size, node_feat_dim)\n",
        "    batch_src_node_embeddings, batch_dst_node_embeddings = \\\n",
        "          model[0].compute_src_dst_node_temporal_embeddings(src_node_ids=batch_src_node_ids,\n",
        "                                                                          dst_node_ids=batch_dst_node_ids,\n",
        "                                                                          node_interact_times=batch_node_interact_times)\n",
        "\n",
        "    # get temporal embedding of negative source and negative destination nodes\n",
        "    # two Tensors, with shape (batch_size, node_feat_dim)\n",
        "    batch_neg_src_node_embeddings, batch_neg_dst_node_embeddings = \\\n",
        "          model[0].compute_src_dst_node_temporal_embeddings(src_node_ids=batch_neg_src_node_ids,\n",
        "                                                                          dst_node_ids=batch_neg_dst_node_ids,\n",
        "                                                                          node_interact_times=batch_node_interact_times)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # get positive and negative probabilities, shape (batch_size, )\n",
        "    positive_probabilities = model[1](input_1=batch_src_node_embeddings, input_2=batch_dst_node_embeddings).squeeze(dim=-1).sigmoid()\n",
        "    negative_probabilities = model[1](input_1=batch_neg_src_node_embeddings, input_2=batch_neg_dst_node_embeddings).squeeze(dim=-1).sigmoid()\n",
        "\n",
        "    predicts = torch.cat([positive_probabilities, negative_probabilities], dim=0)\n",
        "    labels = torch.cat([torch.ones_like(positive_probabilities), torch.zeros_like(negative_probabilities)], dim=0)\n",
        "\n",
        "    loss = loss_func(input=predicts, target=labels)\n",
        "\n",
        "    return predicts, loss, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTN4xURC8Cp1"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_link_prediction(model, neighbor_sampler, evaluate_idx_data_loader, evaluate_data):\n",
        "        model.eval()\n",
        "\n",
        "        model[0].set_neighbor_sampler(neighbor_sampler)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          # store evaluate losses and metrics\n",
        "          evaluate_losses, evaluate_metrics = [], []\n",
        "          evaluate_idx_data_loader_tqdm = tqdm(evaluate_idx_data_loader, ncols=120)\n",
        "          for batch_idx, evaluate_data_indices in enumerate(evaluate_idx_data_loader_tqdm):\n",
        "            predicts, loss, labels = process_batch(batch_idx, evaluate_data_indices, val_neg_edge_sampler, evaluate_data, 'val')\n",
        "\n",
        "            evaluate_losses.append(loss.item())\n",
        "            evaluate_metrics.append(get_link_prediction_metrics(predicts=predicts, labels=labels))\n",
        "\n",
        "            evaluate_idx_data_loader_tqdm.set_description(f'evaluate for the {batch_idx + 1}-th batch, evaluate loss: {loss.item()}')\n",
        "\n",
        "          return evaluate_losses, evaluate_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrNy2nas4gNS"
      },
      "source": [
        "### Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AvAawHm9Rf2L",
        "outputId": "2b35f85f-c68a-40b7-e077-a03e45f78406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dataset has 400000 interactions, involving 400 different nodes\n",
            "The training dataset has 251432 interactions, involving 360 different nodes\n",
            "The validation dataset has 40000 interactions, involving 400 different nodes\n",
            "The test dataset has 40000 interactions, involving 400 different nodes\n",
            "The new node validation dataset has 7542 interactions, involving 304 different nodes\n",
            "The new node test dataset has 8502 interactions, involving 288 different nodes\n",
            "40 nodes were used for the inductive testing, i.e. are never seen during training\n"
          ]
        }
      ],
      "source": [
        " # get data for training, validation and testing\n",
        "node_raw_features, edge_raw_features, full_data, train_data, val_data, test_data, _, _ = \\\n",
        "get_link_prediction_data(dataset_name=args.dataset_name, val_ratio=args.val_ratio, test_ratio=args.test_ratio)\n",
        "\n",
        "# initialize training neighbor sampler to retrieve temporal graph\n",
        "train_neighbor_sampler = get_neighbor_sampler(data=train_data, sample_neighbor_strategy=args.sample_neighbor_strategy,\n",
        "                                                  time_scaling_factor=args.time_scaling_factor, seed=0)\n",
        "\n",
        "# initialize validation and test neighbor sampler to retrieve temporal graph\n",
        "full_neighbor_sampler = get_neighbor_sampler(data=full_data, sample_neighbor_strategy=args.sample_neighbor_strategy,\n",
        "                                                 time_scaling_factor=args.time_scaling_factor, seed=1)\n",
        "\n",
        "# initialize negative samplers, set seeds for validation and testing so negatives are the same across different runs\n",
        "# in the inductive setting, negatives are sampled only amongst other new nodes\n",
        "# train negative edge sampler does not need to specify the seed, but evaluation samplers need to do so\n",
        "train_neg_edge_sampler = NegativeEdgeSampler(src_node_ids=train_data.src_node_ids, dst_node_ids=train_data.dst_node_ids)\n",
        "val_neg_edge_sampler = NegativeEdgeSampler(src_node_ids=full_data.src_node_ids, dst_node_ids=full_data.dst_node_ids, seed=0)\n",
        "test_neg_edge_sampler = NegativeEdgeSampler(src_node_ids=full_data.src_node_ids, dst_node_ids=full_data.dst_node_ids, seed=2)\n",
        "\n",
        "# get data loaders\n",
        "train_idx_data_loader = get_idx_data_loader(indices_list=list(range(len(train_data.src_node_ids))), batch_size=args.batch_size, shuffle=False)\n",
        "val_idx_data_loader = get_idx_data_loader(indices_list=list(range(len(val_data.src_node_ids))), batch_size=args.batch_size, shuffle=False)\n",
        "test_idx_data_loader = get_idx_data_loader(indices_list=list(range(len(test_data.src_node_ids))), batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "val_metric_all_runs, test_metric_all_runs  = [], []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GRR-DP0RKJj6",
        "outputId": "8413852c-a337-4acd-9bbb-e16ac51107a2"
      },
      "outputs": [],
      "source": [
        "\n",
        "for run in range(args.num_runs):\n",
        "    set_random_seed(seed=run)\n",
        "    args.seed = run\n",
        "\n",
        "    args.save_model_name = f'{args.model_name}_seed{args.seed}'\n",
        "    save_model_folder = f\"saved_models/link_prediction/{args.dataset_name}\"\n",
        "    checkpoint_path = os.path.join(save_model_folder, f'{args.save_model_name}.pth')\n",
        "\n",
        "    logger, fh, ch = set_up_logger(args)\n",
        "\n",
        "    run_start_time = time.time()\n",
        "    logger.info(f\"********** Run {run + 1} starts. **********\")\n",
        "\n",
        "    logger.info(f'configuration is {args}')\n",
        "\n",
        "    # Initialize the model\n",
        "    dynamic_backbone = DyGFormer(node_raw_features=node_raw_features, edge_raw_features=edge_raw_features, neighbor_sampler=train_neighbor_sampler,\n",
        "                                time_feat_dim=args.time_feat_dim, channel_embedding_dim=args.channel_embedding_dim, patch_size=args.patch_size,\n",
        "                                num_layers=args.num_layers, num_heads=args.num_heads, dropout=args.dropout,\n",
        "                                max_input_sequence_length=args.max_input_sequence_length, device=args.device)\n",
        "\n",
        "    link_predictor = MergeLayer(input_dim1=node_raw_features.shape[1], input_dim2=node_raw_features.shape[1],\n",
        "                                    hidden_dim=node_raw_features.shape[1], output_dim=1)\n",
        "    model = nn.Sequential(dynamic_backbone, link_predictor)\n",
        "\n",
        "    # log the model structure\n",
        "    logger.info(f'model -> {model}')\n",
        "    logger.info(f'model name: {args.model_name}, #parameters: {get_parameter_sizes(model) * 4} B, '\n",
        "                    f'{get_parameter_sizes(model) * 4 / 1024} KB, {get_parameter_sizes(model) * 4 / 1024 / 1024} MB.')\n",
        "\n",
        "    # Create the optimizer with specified parameters\n",
        "    optimizer = create_optimizer(model=model, optimizer_name=args.optimizer, learning_rate=args.learning_rate, weight_decay=args.weight_decay)\n",
        "\n",
        "    # Convert the model to GPU if available\n",
        "    model = convert_to_gpu(model, device=args.device)\n",
        "\n",
        "    os.makedirs(save_model_folder, exist_ok=True)\n",
        "\n",
        "    # Initialize early stopping mechanism with the given patience and save model parameters\n",
        "    early_stopping = EarlyStopping(patience=args.patience, save_model_folder=save_model_folder,\n",
        "                                       save_model_name=args.save_model_name, logger=logger, model_name=args.model_name)\n",
        "\n",
        "    epoch_resumed = 0\n",
        "    # Load checkpoint if specified and exists\n",
        "    if args.load_checkpoint == True and os.path.exists(checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=args.device)\n",
        "        logger.info(f\"load model {checkpoint_path}\")\n",
        "        early_stopping.load_checkpoint(model, checkpoint)\n",
        "        epoch_resumed = checkpoint['epoch'] + 1\n",
        "        print(f\"Epoch resumed: {epoch_resumed}\")\n",
        "\n",
        "    # Define the binary cross-entropy loss function\n",
        "    loss_func = nn.BCELoss()\n",
        "\n",
        "    for epoch in range(epoch_resumed, args.num_epochs, 1):\n",
        "\n",
        "        # Training for an epoch starts\n",
        "        model.train()\n",
        "\n",
        "        model[0].set_neighbor_sampler(train_neighbor_sampler)\n",
        "        train_losses, train_metrics = [], []\n",
        "        train_idx_data_loader_tqdm = tqdm(train_idx_data_loader, ncols=120)\n",
        "\n",
        "        for batch_idx, train_data_indices in enumerate(train_idx_data_loader_tqdm):\n",
        "          # Process each batch and compute predictions, loss, and labels\n",
        "          predicts, loss, labels = process_batch(batch_idx, train_data_indices, train_neg_edge_sampler, train_data, 'train')\n",
        "\n",
        "          train_losses.append(loss.item())\n",
        "          train_metrics.append(get_link_prediction_metrics(predicts=predicts, labels=labels))\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          train_idx_data_loader_tqdm.set_description(f'Epoch: {epoch}, train for the {batch_idx + 1}-th batch, train loss: {loss.item()}')\n",
        "\n",
        "        # Get validation metrics\n",
        "        val_losses, val_metrics = evaluate_model_link_prediction(model, full_neighbor_sampler, val_idx_data_loader, val_data)\n",
        "\n",
        "        # Log the training and validation metrics\n",
        "        logger.info(f'Epoch: {epoch + 1}, learning rate: {optimizer.param_groups[0][\"lr\"]}, train loss: {np.mean(train_losses):.4f}')\n",
        "        for metric_name in train_metrics[0].keys():\n",
        "            logger.info(f'train {metric_name}, {np.mean([train_metric[metric_name] for train_metric in train_metrics]):.4f}')\n",
        "        logger.info(f'validate loss: {np.mean(val_losses):.4f}')\n",
        "        for metric_name in val_metrics[0].keys():\n",
        "            logger.info(f'validate {metric_name}, {np.mean([val_metric[metric_name] for val_metric in val_metrics]):.4f}')\n",
        "\n",
        "\n",
        "        # perform testing once after test_interval_epochs\n",
        "        if (epoch + 1) % args.test_interval_epochs == 0:\n",
        "            test_losses, test_metrics = evaluate_model_link_prediction(model, full_neighbor_sampler, test_idx_data_loader, test_data)\n",
        "\n",
        "            # Log the test metrics\n",
        "            logger.info(f'test loss: {np.mean(test_losses):.4f}')\n",
        "            for metric_name in test_metrics[0].keys():\n",
        "                logger.info(f'test {metric_name}, {np.mean([test_metric[metric_name] for test_metric in test_metrics]):.4f}')\n",
        "\n",
        "        # select the best model based on all the validate metrics\n",
        "        val_metric_indicator = []\n",
        "        for metric_name in val_metrics[0].keys():\n",
        "          val_metric_indicator.append((metric_name, np.mean([val_metric[metric_name] for val_metric in val_metrics]), True))\n",
        "\n",
        "        early_stop = early_stopping.step(val_metric_indicator, epoch, model)\n",
        "\n",
        "        if early_stop:\n",
        "            break # Stop training if early stopping condition is met\n",
        "\n",
        "    # Load the best model\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=args.device)\n",
        "    early_stopping.load_checkpoint(model, checkpoint)\n",
        "\n",
        "    # Evaluate the best model on the test set\n",
        "    logger.info(f'get final performance on dataset {args.dataset_name}...')\n",
        "    test_losses, test_metrics = evaluate_model_link_prediction(model, full_neighbor_sampler, test_idx_data_loader, test_data)\n",
        "\n",
        "    # Store the evaluation metrics at the current run\n",
        "    test_metric_dict = {}\n",
        "\n",
        "    logger.info(f'test loss: {np.mean(test_losses):.4f}')\n",
        "    for metric_name in test_metrics[0].keys():\n",
        "        average_test_metric = np.mean([test_metric[metric_name] for test_metric in test_metrics])\n",
        "        logger.info(f'test {metric_name}, {average_test_metric:.4f}')\n",
        "        test_metric_dict[metric_name] = average_test_metric\n",
        "\n",
        "    single_run_time = time.time() - run_start_time\n",
        "    logger.info(f'Run {run + 1} cost {single_run_time:.2f} seconds.')\n",
        "    test_metric_all_runs.append(test_metric_dict)\n",
        "\n",
        "    # avoid the overlap of logs\n",
        "    if run < args.num_runs - 1:\n",
        "        logger.removeHandler(fh)\n",
        "        logger.removeHandler(ch)\n",
        "\n",
        "    # Save the results of the current run to a JSON file\n",
        "    result_json = {\"test metrics\": {metric_name: f'{test_metric_dict[metric_name]:.4f}' for metric_name in test_metric_dict}}\n",
        "    result_json = json.dumps(result_json, indent=4)\n",
        "\n",
        "    save_result_folder = f\"saved_results/link_prediction/{args.dataset_name}\"\n",
        "    os.makedirs(save_result_folder, exist_ok=True)\n",
        "    save_result_path = os.path.join(save_result_folder, f\"{args.save_model_name}.json\")\n",
        "\n",
        "    with open(save_result_path, 'w') as file:\n",
        "        file.write(result_json)\n",
        "\n",
        "# store the average metrics at the log of the last run\n",
        "logger.info(f'metrics over {args.num_runs} runs:')\n",
        "\n",
        "# Log the metrics over all runs\n",
        "for metric_name in test_metric_all_runs[0].keys():\n",
        "    logger.info(f'test {metric_name}, {[test_metric_single_run[metric_name] for test_metric_single_run in test_metric_all_runs]}')\n",
        "    logger.info(f'average test {metric_name}, {np.mean([test_metric_single_run[metric_name] for test_metric_single_run in test_metric_all_runs]):.4f} '\n",
        "                    f'± {np.std([test_metric_single_run[metric_name] for test_metric_single_run in test_metric_all_runs], ddof=1):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p5xTFkKR3nB"
      },
      "source": [
        "# Testing & Inferencing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-TENevi-7xP"
      },
      "source": [
        "Choose a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVWI6p02-9nv",
        "outputId": "62c57af9-38d3-4add-e231-9964ba623d0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize the model\n",
        "dynamic_backbone = DyGFormer(node_raw_features=node_raw_features, edge_raw_features=edge_raw_features, neighbor_sampler=train_neighbor_sampler,\n",
        "                                time_feat_dim=args.time_feat_dim, channel_embedding_dim=args.channel_embedding_dim, patch_size=args.patch_size,\n",
        "                                num_layers=args.num_layers, num_heads=args.num_heads, dropout=args.dropout,\n",
        "                                max_input_sequence_length=args.max_input_sequence_length, device=args.device)\n",
        "\n",
        "link_predictor = MergeLayer(input_dim1=node_raw_features.shape[1], input_dim2=node_raw_features.shape[1],\n",
        "                                    hidden_dim=node_raw_features.shape[1], output_dim=1)\n",
        "model = nn.Sequential(dynamic_backbone, link_predictor)\n",
        "\n",
        "model = convert_to_gpu(model, device=args.device)\n",
        "\n",
        "# Load the pretrained model from the specified path\n",
        "load_model_path = f\"saved_models/link_prediction/train_0/DyGFormer_seed2.pth\"\n",
        "checkpoint = torch.load(load_model_path, map_location=args.device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8kIa84g_BdW"
      },
      "source": [
        "Test the model with the testing set (OR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "collapsed": true,
        "id": "5yhKmgCL9v2i",
        "outputId": "cae24011-4c6c-486d-fbcd-558748c1172a"
      },
      "outputs": [],
      "source": [
        "loss_func = nn.BCELoss()\n",
        "test_losses, test_metrics = evaluate_model_link_prediction(model, full_neighbor_sampler, test_idx_data_loader, test_data)\n",
        "\n",
        "# Store the evaluation metrics at the current run\n",
        "test_metric_dict = {}\n",
        "print(f'test loss: {np.mean(test_losses):.4f}')\n",
        "\n",
        "for metric_name in test_metrics[0].keys():\n",
        "    average_test_metric = np.mean([test_metric[metric_name] for test_metric in test_metrics])\n",
        "    print(f'test {metric_name}, {average_test_metric:.4f}')\n",
        "    test_metric_dict[metric_name] = average_test_metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj_Xpwjq_GnX"
      },
      "source": [
        "See how the model performs with custom inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "collapsed": true,
        "id": "20eJQ6dM47Ql",
        "outputId": "0820cddb-f788-49a3-90db-bea0f04bc425"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"inference_df\",\n  \"rows\": 9679,\n  \"fields\": [\n    {\n      \"column\": \"first_nodes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 399,\n        \"num_unique_values\": 400,\n        \"samples\": [\n          209,\n          280,\n          33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"second_nodes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 399,\n        \"num_unique_values\": 400,\n        \"samples\": [\n          266,\n          171,\n          251\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "inference_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7fafea0b-c131-428e-a029-7f0f5dc4c756\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>first_nodes</th>\n",
              "      <th>second_nodes</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>133</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>143</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9979</th>\n",
              "      <td>399</td>\n",
              "      <td>352</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9977</th>\n",
              "      <td>399</td>\n",
              "      <td>363</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9989</th>\n",
              "      <td>399</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9991</th>\n",
              "      <td>399</td>\n",
              "      <td>393</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9980</th>\n",
              "      <td>399</td>\n",
              "      <td>399</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9679 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fafea0b-c131-428e-a029-7f0f5dc4c756')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7fafea0b-c131-428e-a029-7f0f5dc4c756 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7fafea0b-c131-428e-a029-7f0f5dc4c756');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d2089af2-7303-4168-96d6-72b23132f710\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d2089af2-7303-4168-96d6-72b23132f710')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d2089af2-7303-4168-96d6-72b23132f710 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9c44d096-00f8-4620-aa9b-ade233143511\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('inference_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9c44d096-00f8-4620-aa9b-ade233143511 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('inference_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      first_nodes  second_nodes  link\n",
              "15              0            30     1\n",
              "20              0            34     1\n",
              "5               0            52     1\n",
              "7               0           133     1\n",
              "6               0           143     1\n",
              "...           ...           ...   ...\n",
              "9979          399           352     1\n",
              "9977          399           363     1\n",
              "9989          399           377     1\n",
              "9991          399           393     1\n",
              "9980          399           399     1\n",
              "\n",
              "[9679 rows x 3 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set threshold and data generation parameters\n",
        "threshold = 0.31 # should be around 0.3\n",
        "each_occurance = 100 # must be < 400\n",
        "size = 10000 # must be < 160000 (400 * 400)\n",
        "\n",
        "# Generate an array of node IDs with specified occurrences (array of 100 times one, 100 times two, etc.)\n",
        "base_array = np.repeat(np.arange(0, 400), each_occurance)\n",
        "first_node_ids = np.sort(np.random.choice(base_array, size=size, replace=False))\n",
        "second_node_ids = np.random.choice(base_array, size=size, replace=False)\n",
        "node_interact_times = np.zeros(size)\n",
        "\n",
        "# unique, counts = np.unique(second_node_ids, return_counts=True)\n",
        "# print(f\"occurance: {dict(zip(unique, counts))}\")\n",
        "\n",
        "# Compute source and destination node temporal embeddings using the model\n",
        "first_node_embeddings, second_node_embeddings = \\\n",
        "model[0].compute_src_dst_node_temporal_embeddings(src_node_ids=first_node_ids,\n",
        "                                                  dst_node_ids=second_node_ids,\n",
        "                                                  node_interact_times=node_interact_times)\n",
        "\n",
        "# Predict link probabilities\n",
        "probabilities = model[1](input_1=first_node_embeddings, input_2=second_node_embeddings).squeeze(dim=-1).sigmoid()\n",
        "\n",
        "# Determine the links based on the threshold\n",
        "link = np.where(probabilities.detach().cpu() > threshold, 1, 0)\n",
        "\n",
        "# Create a DataFrame to store the inference results\n",
        "inference_df = pd.DataFrame({\n",
        "    'first_nodes': first_node_ids,\n",
        "    'second_nodes': second_node_ids,\n",
        "    'link': link\n",
        "    })\n",
        "\n",
        "inference_df = inference_df.drop_duplicates()\n",
        "inference_df = inference_df.sort_values(by=['first_nodes', 'link', 'second_nodes'])\n",
        "inference_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uV4dkRY-qC7H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SrOiGmrTQBmv",
        "8Zn_Gw0Qvb-x",
        "6jir_UjtyTua",
        "YrNy2nas4gNS",
        "4p5xTFkKR3nB"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
